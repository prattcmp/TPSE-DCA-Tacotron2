{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tacotron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPlHwlf9LrTgPf561vUmoe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bshall/Tacotron/blob/main/tacotron-demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd1Vu8s-oly8"
      },
      "source": [
        "# Tacotron (with Dynamic Convolution Attention)\n",
        "\n",
        "A PyTorch implementation of [Location-Relative Attention Mechanisms For Robust Long-Form Speech Synthesis](https://arxiv.org/abs/1910.10288). \n",
        "\n",
        "Audio samples can be found [here](https://bshall.github.io/Tacotron/).\n",
        "\n",
        "Demo for https://github.com/bshall/Tacotron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdr0Xq1epOOc"
      },
      "source": [
        "Install the necessary packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6BZfOK1htR5"
      },
      "source": [
        "!pip install -q omegaconf\n",
        "!pip install -q librosa==0.8.0\n",
        "!pip install -q univoc\n",
        "!pip install -q tacotron"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dsy_0WIhvIo"
      },
      "source": [
        "import torch\n",
        "import soundfile as sf\n",
        "from univoc import Vocoder\n",
        "from tacotron import load_cmudict, text_to_id, Tacotron\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xb2f-21nn2Q"
      },
      "source": [
        "Download pretrained weights for the vocoder and move to the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv6AS1ZtkRr8"
      },
      "source": [
        "vocoder = Vocoder.from_pretrained(\n",
        "    \"https://github.com/bshall/UniversalVocoding/releases/download/v0.2/univoc-ljspeech-7mtpaq.pt\"\n",
        ").cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJppnjFCnwRh"
      },
      "source": [
        "Download pretrained weights for tacotron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh9s-8ZDWRf5"
      },
      "source": [
        "tacotron = Tacotron.from_pretrained(\n",
        "    \"https://github.com/bshall/Tacotron/releases/download/v0.1/tacotron-ljspeech-yspjx3.pt\"\n",
        ").cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVfNhClFn25w"
      },
      "source": [
        "Load the CMU pronunciation dictionary and add the pronunciation of \"PyTorch\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJKStkw_XTU9"
      },
      "source": [
        "cmudict = load_cmudict()\n",
        "cmudict[\"PYTORCH\"] = \"P AY1 T AO2 R CH\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t9P8M64oCZY"
      },
      "source": [
        "The text to be synthesized:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB-g3VKgoEW_"
      },
      "source": [
        "text = \"A PyTorch implementation of location-relative attention mechanisms for long-form speech synthesis.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miBeiQEXoQCH"
      },
      "source": [
        "Synthesize the audio!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNQJCGnIll2s"
      },
      "source": [
        "x = torch.LongTensor(text_to_id(text, cmudict)).unsqueeze(0).cuda()\n",
        "with torch.no_grad():\n",
        "    mel, alpha = tacotron.generate(x)\n",
        "    wav, sr = vocoder.generate(mel.transpose(1, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFcbRt4Yob_3"
      },
      "source": [
        "Listen to the results (IPython normalizes the audio so the result is louder than it would normally be)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut4sD-1imFTV"
      },
      "source": [
        "Audio(wav, rate=sr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIvv6DQ2ogC2"
      },
      "source": [
        "and plot the attention matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIfYMI5DmHHV"
      },
      "source": [
        "plt.imshow(alpha.squeeze().cpu().numpy(), vmin=0, vmax=0.8, origin=\"lower\")\n",
        "plt.xlabel(\"Decoder steps\")\n",
        "plt.ylabel(\"Encoder steps\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M27-ErBgjy4c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}